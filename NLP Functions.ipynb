{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_libs():\n",
    "    \"\"\"Imports all Python libraries needed for basic Topic Modeling\"\"\"\n",
    "\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "import sys #only needed to determine Python version number\n",
    "import matplotlib #only needed to determine Matplotlib version number\n",
    "from sqlalchemy import create_engine, MetaData, Table, select\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "# nltk.download()\n",
    "#import rpy2\n",
    "import spacy\n",
    "import en_core_web_sm  # or any other model you downloaded via spacy download or pip\n",
    "nlp = en_core_web_sm.load()\n",
    "#import gensim\n",
    "\n",
    "# load the R package ISLR\n",
    "# infert = com.importr(\"ISLR\")\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "#Import and assign WordNetLemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "#Set up spaCy\n",
    "import spacy\n",
    "import en_core_web_sm  # or any other model you downloaded via spacy download or pip\n",
    "nlp = en_core_web_sm.load()\n",
    "from spacy.en import English\n",
    "parser = English()\n",
    "from spacy.en.word_sets import STOP_WORDS\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_cnxn():\n",
    "    \"\"\"Connect to our SQL Server using Windows authentication\"\"\"\n",
    "    # assign server and db\n",
    "server = 'ES11vADOSQL006'\n",
    "db = 'master'\n",
    "\n",
    "# Create the connection to all dbs\n",
    "cnxn = pyodbc.connect('DRIVER={ODBC Driver 11 for SQL Server};SERVER=ES11vADOSQL006;DATABASE=master;Trusted_Connection=yes;')\n",
    "# Connect to ORD_INT\n",
    "#ORD_INT = pyodbc.connect('DRIVER={ODBC Driver 11 for SQL Server};SERVER=ES11vADOSQL006;DATABASE=ORD_INT;Trusted_Connection=yes;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_libs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_cnxn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset():\n",
    "    raw_sql_query = str(input(\"Enter your SQL query: \"))\n",
    "    if raw_sql_query:\n",
    "        return\n",
    "        df = pd.read_sql_query(raw_sql_query, index_col=None, coerce_float=True, params=None, parse_dates=None, chunksize=None) \n",
    "        df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sql_query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-8cdc8d794030>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mraw_sql_query\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter your SQL query: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msql_query\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\"\"\" + raw_sql_query + \"\"\"\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msql3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msql_query\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnxn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sql_query' is not defined"
     ]
    }
   ],
   "source": [
    "def dataset():\n",
    "    \"\"\"This functions allows you to input a SQL query and it will be transformed into a Pandas dataframe\"\"\"\n",
    "    raw_sql_query = input(\"Enter your SQL query: \")\n",
    "    sql_query = \"\"\"\"\" + raw_sql_query + \"\"\"\"\" \n",
    "sql3 = sql_query \n",
    "df = pd.io.sql.read_sql(sql3, cnxn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.parts_of_speech import PROPN\n",
    "\n",
    "def is_proper_noun(token):\n",
    "    if token.doc.is_tagged is False:  # check if the document was POS-tagged\n",
    "        raise ValueError('token is not POS-tagged')\n",
    "\n",
    "    return token.pos == PROPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-1c065df40cf6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m for doc in nlp.pipe(df['col'].astype('unicode').values, batch_size=9845,\n\u001b[0m\u001b[0;32m      9\u001b[0m                         n_threads=3):\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_parsed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "def nlp_tok_lem_pos():\n",
    "    \"\"\"This function creates 3 new columns of tokens, lemmas, and pos tags respectively\"\"\"\n",
    "\n",
    "tokens = []\n",
    "lemma = []\n",
    "pos = []\n",
    "\n",
    "for doc in nlp.pipe(df['col'].astype('unicode').values, batch_size=9845,\n",
    "                        n_threads=3):\n",
    "    if doc.is_parsed:\n",
    "        tokens.append([n.text for n in doc if not n.is_punct and not n.is_stop and not n.is_space and not n.like_url and not is_proper_noun(n)])\n",
    "        lemma.append([n.lemma_ for n in doc if not n.is_punct and not n.is_stop and not n.is_space and not n.like_url and not is_proper_noun(n)])\n",
    "        pos.append([n.pos_ for n in doc if not n.is_punct and not n.is_stop and not n.is_space and not n.like_url and not is_proper_noun(n)])\n",
    "    else:\n",
    "        tokens.append(None)\n",
    "        lemma.append(None)\n",
    "        pos.append(None)\n",
    "\n",
    "df['s_tokens_col'] = tokens\n",
    "df['s_lemmas_col'] = lemma \n",
    "df['s_pos_col'] = pos\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
