{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling\n",
    "Liz McQuillan\n",
    "4/30/2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling Uses\n",
    "\n",
    "Given a large corpus of text, Topic Modeling is one way to get a general overview of the different topics within the text, the proportion of these themes, or even find hidden patterns within the corpus. This is different from rules-based approaches in text mining (like keyword searches), in that it's an unsupervised technique for finding linked groups of words (\"topics\") in a large corpus. \n",
    "\n",
    "Topics are generally defined as \"a repeating pattern of co-occuring terms\". Topic Models are used for clustering documents, feature selection, and information retrieval among other things. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools and Methods\n",
    "\n",
    "There are a handful of techniques for getting topics from text, including Term Frequency-Inverse Document Frequency (TF-IDF), NonNegative Matrix Factorization (NMF), Latent Semantic Analysis (LSA), Heirarchical Dirichlet Process (HPD), and Latent Dirichlet Allocation (LDA). LDA is the most popular topic modeling technique, so that's what I'll focus on here. \n",
    "\n",
    "For LDA, Gensim is the premier Python Package. scikit-learn has some alternative algorithms, like NMF, but doesn't have LDA (LDA in scikit-learn = Linear Discriminant Analysis).\n",
    "\n",
    "LDA is a matrix factorization technique, and thus requires a document-term matrix as input. LDA takes a document-term matrix and tries to figure out which topics would create those documents based on the assumption that documents are produced from a bunch of topics which themselves are made up of words based on various probability distributions. \n",
    "\n",
    "The interim steps in this process include converting the document-term matrix into two matrices, a document-topics matric and a topic-terms matrix, which contain initial document/topic and topic/word distributions. Here's where LDA actually starts working. LDA aims to improve these matrices through a variety of sampling techniques. Basically, LDA iterates thorugh each word for each document to adjust the topic-word assignment (assuming all current topic/word assignments are correct) until a steady state is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from sqlalchemy import create_engine, MetaData, Table, select\n",
    "import sklearn\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import spacy\n",
    "import en_core_web_sm  # or any other model you downloaded via spacy download or pip\n",
    "nlp = en_core_web_sm.load()\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data\n",
    "Let's pull in some text data to work with. \n",
    "\n",
    "We're going to use a subset of the 20 Newsgroups dataset, via Sci-Kit Learn. \n",
    "\n",
    "By using the Pandas package we can enforce a tabular structure on the data. This is especially helpful if you're used to working in SQL, SAS, or Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "df = pd.DataFrame([newsgroups.data, newsgroups.target.tolist()]).T\n",
    "df.columns = ['text', 'target']\n",
    "targets = pd.DataFrame( newsgroups.target_names)\n",
    "targets.columns=['title']\n",
    "news_data = pd.merge(df, targets, left_on='target', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create the connection to all dbs\n",
    "cnxn = pyodbc.connect('DRIVER={ODBC Driver 11 for SQL Server};SERVER=ES11vADOSQL006;DATABASE=master;Trusted_Connection=yes;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIPImprovementPlan1</th>\n",
       "      <th>TIPActionPlan</th>\n",
       "      <th>TIPTimelinePlan</th>\n",
       "      <th>TIPSupportPlan</th>\n",
       "      <th>TIPAssessmentPlan</th>\n",
       "      <th>TIP_all_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1E: Designing Coherent Instruction: Design les...</td>\n",
       "      <td>1E: Designing Coherent Instruction:\\r\\n\\t• Des...</td>\n",
       "      <td>See above</td>\n",
       "      <td>1) You will schedule inter-visitations to obse...</td>\n",
       "      <td>In our second and third meetings, we will revi...</td>\n",
       "      <td>1E: Designing Coherent Instruction: Design les...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Based on prior observations from the 2015-2016...</td>\n",
       "      <td>For 1e:\\r\\n\\r\\nA) Establish regular time(s) to...</td>\n",
       "      <td>See action steps/activities for specifics</td>\n",
       "      <td>1) Choose PD Cycle to support the steps in you...</td>\n",
       "      <td>You are responsible for gathering and providin...</td>\n",
       "      <td>Based on prior observations from the 2015-2016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Based on prior observations and feedback from ...</td>\n",
       "      <td>For 1e:\\r\\n\\r\\n1. Establish regular time(s) to...</td>\n",
       "      <td>See action steps/activities for specific time ...</td>\n",
       "      <td>1) Choose to participate in a  PD cycle to sup...</td>\n",
       "      <td>You are responsible for gathering and providin...</td>\n",
       "      <td>Based on prior observations and feedback from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>After reviewing last year's TIP, MOSL assessme...</td>\n",
       "      <td>1:Addressing the learning needs of small group...</td>\n",
       "      <td>Refer to the timelines included at the end of ...</td>\n",
       "      <td>1.  Mr. Louie will participate in 1:1 coaching...</td>\n",
       "      <td>1.  In our next 2 meetings we will review the ...</td>\n",
       "      <td>After reviewing last year's TIP, MOSL assessme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. Having learning activities aligned with the...</td>\n",
       "      <td>1. For improved alignment of learning activiti...</td>\n",
       "      <td>See above-ongoing</td>\n",
       "      <td>-Collaborate with your co-teachers to follow T...</td>\n",
       "      <td>1. Learning activities are aligned with the in...</td>\n",
       "      <td>1. Having learning activities aligned with the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 TIPImprovementPlan1  \\\n",
       "0  1E: Designing Coherent Instruction: Design les...   \n",
       "1  Based on prior observations from the 2015-2016...   \n",
       "2  Based on prior observations and feedback from ...   \n",
       "3  After reviewing last year's TIP, MOSL assessme...   \n",
       "4  1. Having learning activities aligned with the...   \n",
       "\n",
       "                                       TIPActionPlan  \\\n",
       "0  1E: Designing Coherent Instruction:\\r\\n\\t• Des...   \n",
       "1  For 1e:\\r\\n\\r\\nA) Establish regular time(s) to...   \n",
       "2  For 1e:\\r\\n\\r\\n1. Establish regular time(s) to...   \n",
       "3  1:Addressing the learning needs of small group...   \n",
       "4  1. For improved alignment of learning activiti...   \n",
       "\n",
       "                                     TIPTimelinePlan  \\\n",
       "0                                          See above   \n",
       "1          See action steps/activities for specifics   \n",
       "2  See action steps/activities for specific time ...   \n",
       "3  Refer to the timelines included at the end of ...   \n",
       "4                                  See above-ongoing   \n",
       "\n",
       "                                      TIPSupportPlan  \\\n",
       "0  1) You will schedule inter-visitations to obse...   \n",
       "1  1) Choose PD Cycle to support the steps in you...   \n",
       "2  1) Choose to participate in a  PD cycle to sup...   \n",
       "3  1.  Mr. Louie will participate in 1:1 coaching...   \n",
       "4  -Collaborate with your co-teachers to follow T...   \n",
       "\n",
       "                                   TIPAssessmentPlan  \\\n",
       "0  In our second and third meetings, we will revi...   \n",
       "1  You are responsible for gathering and providin...   \n",
       "2  You are responsible for gathering and providin...   \n",
       "3  1.  In our next 2 meetings we will review the ...   \n",
       "4  1. Learning activities are aligned with the in...   \n",
       "\n",
       "                                         TIP_all_txt  \n",
       "0  1E: Designing Coherent Instruction: Design les...  \n",
       "1  Based on prior observations from the 2015-2016...  \n",
       "2  Based on prior observations and feedback from ...  \n",
       "3  After reviewing last year's TIP, MOSL assessme...  \n",
       "4  1. Having learning activities aligned with the...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull data from SQL Server\n",
    "#Create an additional column with all text concatenated\n",
    "sql3 = \"\"\"\n",
    "SELECT TIPImprovementPlan1, TIPActionPlan, TIPTimelinePlan, TIPSupportPlan, TIPAssessmentPlan,(TIPImprovementPlan1 + ' ' + TIPActionPlan + ' ' + TIPTimeLinePlan + ' ' + TIPSupportPlan + ' ' + TIPAssessmentPlan) as TIP_all_txt\n",
    "FROM [APPR_EXT].[dbo].[APPRTIP]\n",
    "where IsSubmitted = 'Y' and TIPEndedAppeal = 'N' and FiscalYear = 2017\n",
    "\"\"\"\n",
    "APPRTIP = pd.io.sql.read_sql(sql3, cnxn) #assign the SQL query to a pandas dataframe called APPRTIP\n",
    "APPRTIP.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the Data\n",
    "Then we'll do some basic pre-processing to clean the data\n",
    "\n",
    "See this page (https://github.com/LizMGagne/NLP/blob/master/NLP%20Pre-processing.ipynb) for a more thorough explaination of NLP pre-processing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIPImprovementPlan1</th>\n",
       "      <th>TIPActionPlan</th>\n",
       "      <th>TIPTimelinePlan</th>\n",
       "      <th>TIPSupportPlan</th>\n",
       "      <th>TIPAssessmentPlan</th>\n",
       "      <th>TIP_all_txt</th>\n",
       "      <th>tokens_all_txt</th>\n",
       "      <th>lemmas_all_txt</th>\n",
       "      <th>pos_all_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1E: Designing Coherent Instruction: Design les...</td>\n",
       "      <td>1E: Designing Coherent Instruction:\\r\\n\\t• Des...</td>\n",
       "      <td>See above</td>\n",
       "      <td>1) You will schedule inter-visitations to obse...</td>\n",
       "      <td>In our second and third meetings, we will revi...</td>\n",
       "      <td>1E: Designing Coherent Instruction: Design les...</td>\n",
       "      <td>[Designing, Coherent, Instruction, Design, les...</td>\n",
       "      <td>[designing, coherent, instruction, design, les...</td>\n",
       "      <td>[PROPN, PROPN, PROPN, PROPN, VERB, ADV, VERB, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Based on prior observations from the 2015-2016...</td>\n",
       "      <td>For 1e:\\r\\n\\r\\nA) Establish regular time(s) to...</td>\n",
       "      <td>See action steps/activities for specifics</td>\n",
       "      <td>1) Choose PD Cycle to support the steps in you...</td>\n",
       "      <td>You are responsible for gathering and providin...</td>\n",
       "      <td>Based on prior observations from the 2015-2016...</td>\n",
       "      <td>[Based, prior, observations, school, year, add...</td>\n",
       "      <td>[base, prior, observation, school, year, addit...</td>\n",
       "      <td>[VERB, ADJ, NOUN, NOUN, NOUN, NOUN, VERB, VERB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Based on prior observations and feedback from ...</td>\n",
       "      <td>For 1e:\\r\\n\\r\\n1. Establish regular time(s) to...</td>\n",
       "      <td>See action steps/activities for specific time ...</td>\n",
       "      <td>1) Choose to participate in a  PD cycle to sup...</td>\n",
       "      <td>You are responsible for gathering and providin...</td>\n",
       "      <td>Based on prior observations and feedback from ...</td>\n",
       "      <td>[Based, prior, observations, feedback, previou...</td>\n",
       "      <td>[base, prior, observation, feedback, previous,...</td>\n",
       "      <td>[VERB, ADJ, NOUN, VERB, ADJ, NOUN, VERB, VERB,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>After reviewing last year's TIP, MOSL assessme...</td>\n",
       "      <td>1:Addressing the learning needs of small group...</td>\n",
       "      <td>Refer to the timelines included at the end of ...</td>\n",
       "      <td>1.  Mr. Louie will participate in 1:1 coaching...</td>\n",
       "      <td>1.  In our next 2 meetings we will review the ...</td>\n",
       "      <td>After reviewing last year's TIP, MOSL assessme...</td>\n",
       "      <td>[After, reviewing, year, TIP, MOSL, assessment...</td>\n",
       "      <td>[after, review, year, tip, mosl, assessment, o...</td>\n",
       "      <td>[ADP, VERB, NOUN, PROPN, PROPN, NOUN, ADJ, NOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. Having learning activities aligned with the...</td>\n",
       "      <td>1. For improved alignment of learning activiti...</td>\n",
       "      <td>See above-ongoing</td>\n",
       "      <td>-Collaborate with your co-teachers to follow T...</td>\n",
       "      <td>1. Learning activities are aligned with the in...</td>\n",
       "      <td>1. Having learning activities aligned with the...</td>\n",
       "      <td>[Having, learning, activities, aligned, instru...</td>\n",
       "      <td>[have, learn, activity, align, instructional, ...</td>\n",
       "      <td>[VERB, VERB, NOUN, VERB, ADJ, NOUN, VERB, ADJ,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 TIPImprovementPlan1  \\\n",
       "0  1E: Designing Coherent Instruction: Design les...   \n",
       "1  Based on prior observations from the 2015-2016...   \n",
       "2  Based on prior observations and feedback from ...   \n",
       "3  After reviewing last year's TIP, MOSL assessme...   \n",
       "4  1. Having learning activities aligned with the...   \n",
       "\n",
       "                                       TIPActionPlan  \\\n",
       "0  1E: Designing Coherent Instruction:\\r\\n\\t• Des...   \n",
       "1  For 1e:\\r\\n\\r\\nA) Establish regular time(s) to...   \n",
       "2  For 1e:\\r\\n\\r\\n1. Establish regular time(s) to...   \n",
       "3  1:Addressing the learning needs of small group...   \n",
       "4  1. For improved alignment of learning activiti...   \n",
       "\n",
       "                                     TIPTimelinePlan  \\\n",
       "0                                          See above   \n",
       "1          See action steps/activities for specifics   \n",
       "2  See action steps/activities for specific time ...   \n",
       "3  Refer to the timelines included at the end of ...   \n",
       "4                                  See above-ongoing   \n",
       "\n",
       "                                      TIPSupportPlan  \\\n",
       "0  1) You will schedule inter-visitations to obse...   \n",
       "1  1) Choose PD Cycle to support the steps in you...   \n",
       "2  1) Choose to participate in a  PD cycle to sup...   \n",
       "3  1.  Mr. Louie will participate in 1:1 coaching...   \n",
       "4  -Collaborate with your co-teachers to follow T...   \n",
       "\n",
       "                                   TIPAssessmentPlan  \\\n",
       "0  In our second and third meetings, we will revi...   \n",
       "1  You are responsible for gathering and providin...   \n",
       "2  You are responsible for gathering and providin...   \n",
       "3  1.  In our next 2 meetings we will review the ...   \n",
       "4  1. Learning activities are aligned with the in...   \n",
       "\n",
       "                                         TIP_all_txt  \\\n",
       "0  1E: Designing Coherent Instruction: Design les...   \n",
       "1  Based on prior observations from the 2015-2016...   \n",
       "2  Based on prior observations and feedback from ...   \n",
       "3  After reviewing last year's TIP, MOSL assessme...   \n",
       "4  1. Having learning activities aligned with the...   \n",
       "\n",
       "                                      tokens_all_txt  \\\n",
       "0  [Designing, Coherent, Instruction, Design, les...   \n",
       "1  [Based, prior, observations, school, year, add...   \n",
       "2  [Based, prior, observations, feedback, previou...   \n",
       "3  [After, reviewing, year, TIP, MOSL, assessment...   \n",
       "4  [Having, learning, activities, aligned, instru...   \n",
       "\n",
       "                                      lemmas_all_txt  \\\n",
       "0  [designing, coherent, instruction, design, les...   \n",
       "1  [base, prior, observation, school, year, addit...   \n",
       "2  [base, prior, observation, feedback, previous,...   \n",
       "3  [after, review, year, tip, mosl, assessment, o...   \n",
       "4  [have, learn, activity, align, instructional, ...   \n",
       "\n",
       "                                         pos_all_txt  \n",
       "0  [PROPN, PROPN, PROPN, PROPN, VERB, ADV, VERB, ...  \n",
       "1  [VERB, ADJ, NOUN, NOUN, NOUN, NOUN, VERB, VERB...  \n",
       "2  [VERB, ADJ, NOUN, VERB, ADJ, NOUN, VERB, VERB,...  \n",
       "3  [ADP, VERB, NOUN, PROPN, PROPN, NOUN, ADJ, NOU...  \n",
       "4  [VERB, VERB, NOUN, VERB, ADJ, NOUN, VERB, ADJ,...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = []\n",
    "lemma = []\n",
    "pos = []\n",
    "\n",
    "for doc in nlp.pipe(APPRTIP['TIP_all_txt'].astype('unicode').values, batch_size=100,\n",
    "                        n_threads=3):\n",
    "    if doc.is_parsed:\n",
    "        tokens.append([n.text for n in doc if not n.is_punct and not n.is_stop and not n.is_space and not n.like_url and n.is_alpha])\n",
    "        lemma.append([n.lemma_ for n in doc if not n.is_punct and not n.is_stop and not n.is_space and not n.like_url and n.is_alpha])\n",
    "        pos.append([n.pos_ for n in doc if not n.is_punct and not n.is_stop and not n.is_space and not n.like_url and n.is_alpha])\n",
    "    else:\n",
    "        tokens.append(None)\n",
    "        lemma.append(None)\n",
    "        pos.append(None)\n",
    "\n",
    "APPRTIP['tokens_all_txt'] = tokens\n",
    "APPRTIP['lemmas_all_txt'] = lemma\n",
    "APPRTIP['pos_all_txt'] = pos\n",
    "\n",
    "APPRTIP.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the Corpus\n",
    "Now, let's take only the lemmas to build the dictionary and doc-term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the term dictionary of our corpus, where every unique term is assigned an index. \n",
    "dictionary = corpora.Dictionary(lemma)\n",
    "\n",
    "# Converting corpus into Document-Term Matrix using dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in lemma]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Topic Model\n",
    "Now that we have the dictionary and doc-term matrix we can start building the LDA model. LDA requires the number of topics as an input. I've also specified chunksize (number of docs to be used in each training \"chunk\"), update_every (how often the model should be updated), and passes (the number of training passes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.LdaModel\n",
    "\n",
    "# Running and Training LDA model on the document term matrix.\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=25, random_state = 100, update_every=1, chunksize = 100, id2word = dictionary, passes=100, alpha='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the Topics\n",
    "Using print_topics will print keywords for each topic and the relative weights of each word.\n",
    "\n",
    "##### Interpreting Topics\n",
    "In the case of our data Topic 0 is represented as (0, '0.044*\"student\" + 0.044*\"lesson\" + 0.044*\"activity\"')\n",
    "\n",
    "This means the top words that contribute to the topic are \"student\", \"lesson\", and \"activity\" and the weights represent the importance of each word. LDA requires a good deal of interpretation - it will not label the topics with a word or phrase, so it's up to the analyst to determine how to label each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.151*\"science\" + 0.042*\"tuesday\" + 0.021*\"expand\"'),\n",
       " (1, '0.069*\"student\" + 0.051*\"discussion\" + 0.032*\"use\"'),\n",
       " (2, '0.149*\"scholar\" + 0.017*\"appeal\" + 0.013*\"furthermore\"'),\n",
       " (3, '0.113*\"content\" + 0.050*\"knowledge\" + 0.043*\"concept\"'),\n",
       " (4, '0.047*\"activity\" + 0.041*\"student\" + 0.038*\"lesson\"'),\n",
       " (5, '0.311*\"teacher\" + 0.106*\"the\" + 0.018*\"sandi\"'),\n",
       " (6, '0.027*\"year\" + 0.027*\"meeting\" + 0.024*\"observation\"'),\n",
       " (7, '0.110*\"student\" + 0.084*\"behavior\" + 0.057*\"classroom\"'),\n",
       " (8, '0.021*\"pedagogical\" + 0.020*\"enhance\" + 0.020*\"approach\"'),\n",
       " (9, '0.069*\"staff\" + 0.065*\"reading\" + 0.058*\"group\"'),\n",
       " (10, '0.098*\"o\" + 0.036*\"submit\" + 0.022*\"goldstein\"'),\n",
       " (11, '0.155*\"domain\" + 0.082*\"by\" + 0.071*\"component\"'),\n",
       " (12, '0.054*\"rigorous\" + 0.047*\"rigor\" + 0.042*\"task\"'),\n",
       " (13, '0.079*\"student\" + 0.030*\"step\" + 0.028*\"action\"'),\n",
       " (14, '0.036*\"project\" + 0.033*\"art\" + 0.020*\"evaluator\"'),\n",
       " (15, '0.203*\"principal\" + 0.127*\"assistant\" + 0.026*\"ms\"'),\n",
       " (16, '0.161*\"b\" + 0.129*\"c\" + 0.075*\"d\"'),\n",
       " (17, '0.079*\"period\" + 0.046*\"curriculum\" + 0.025*\"calendar\"'),\n",
       " (18, '0.099*\"student\" + 0.084*\"question\" + 0.039*\"discussion\"'),\n",
       " (19, '0.113*\"feedback\" + 0.068*\"improve\" + 0.062*\"performance\"'),\n",
       " (20, '0.060*\"student\" + 0.053*\"lesson\" + 0.039*\"plan\"'),\n",
       " (21, '0.072*\"language\" + 0.028*\"writing\" + 0.027*\"vocabulary\"'),\n",
       " (22, '0.093*\"student\" + 0.053*\"learning\" + 0.030*\"lesson\"'),\n",
       " (23, '0.031*\"class\" + 0.019*\"check\" + 0.017*\"student\"'),\n",
       " (24, '0.241*\"-PRON-\" + 0.030*\"discuss\" + 0.021*\"need\"')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(ldamodel.print_topics(num_topics=25, num_words=3))\n",
    "ldamodel.print_topics(num_topics=25, num_words=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Optimal Number of Topics\n",
    "\n",
    "There's some disagreement among data scientists about what the best number of topics even means - is it coherence? comprehensiveness? something else? Personally, I err on the side of interpretability and meaningfulness - I don't want the same words repeated over and over throughout the topics. In practice this means building a handful of models with various k values and picking the one with the highest coherence score. The coherence score for our model is ~0.4 here - not ideal, but not terrible. It's a bit of a balancing act getting a \"good\" coehrence score, while maintaining an aceptable level of readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -6.17109307576\n",
      "\n",
      "Coherence Score:  0.41855547143\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', ldamodel.log_perplexity(doc_term_matrix))  #lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=ldamodel, texts=lemma, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda) #higher is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the LDA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the LDA model are completely dependent on the data used (garbage in = garbage out). Since doc-term matrices are typically sparse, dimensionailty reduction may improve the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Filter\n",
    "Since terms which appear less often in the corpus are also less likely to appear in the results, the lowest frequency terms can be excluded. Some basic exploratory analysis of term frequencies is required to pinpoint an appropriate frequency threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts of Speech Filter\n",
    "Earlier in this code some types of strings were filtered out (stop words, numbers, etc). Depending on the data being analyzed it may improve the model's accuracy to strip out further types of words. Whether these are additional filler words (i.e. \"within\", \"may\", etc) or some other words which occur in ways that render them meaningless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Pooling\n",
    "There's research to support creating macro-documents for LDA training might increase the accuracy and/or usability of topics by enriching the content in each document (http://users.cecs.anu.edu.au/~ssanner/Papers/sigir13.pdf). However, the documents being used here are quite long (average ~700 words) and assumedy have sufficient co-occurance of terms within each document to be used for training without aggregation. If the documents being analyzed were shorter (like Tweets, texts, and the like) it may be worthwhile to aggregate at some level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning Documents to Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contribution</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.2227</td>\n",
       "      <td>student, step, action, learning, lesson, area,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.2331</td>\n",
       "      <td>student, lesson, plan, assessment, work, datum...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.2790</td>\n",
       "      <td>student, step, action, learning, lesson, area,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.2897</td>\n",
       "      <td>student, lesson, plan, assessment, work, datum...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8550</td>\n",
       "      <td>activity, student, lesson, area, action, step,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contribution  \\\n",
       "0            0            13.0                   0.2227   \n",
       "1            1            20.0                   0.2331   \n",
       "2            2            13.0                   0.2790   \n",
       "3            3            20.0                   0.2897   \n",
       "4            4             4.0                   0.8550   \n",
       "\n",
       "                                            Keywords  Text  \n",
       "0  student, step, action, learning, lesson, area,...     0  \n",
       "1  student, lesson, plan, assessment, work, datum...     1  \n",
       "2  student, step, action, learning, lesson, area,...     2  \n",
       "3  student, lesson, plan, assessment, work, datum...     3  \n",
       "4  activity, student, lesson, area, action, step,...     4  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=ldamodel, corpus=lemma, texts=dictionary):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get dominant topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the dominant topic, percent Contribution and keywords for each doc\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=ldamodel, corpus=doc_term_matrix, texts=dictionary)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contribution', 'Keywords', 'Text']\n",
    "\n",
    "# Print the first 5 rows\n",
    "df_dominant_topic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Document That's Representitive of Each Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contribution</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5216</td>\n",
       "      <td>student, discussion, use, questioning, questio...</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3238</td>\n",
       "      <td>content, knowledge, concept, plan, lesson, ped...</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9551</td>\n",
       "      <td>activity, student, lesson, area, action, step,...</td>\n",
       "      <td>1752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5604</td>\n",
       "      <td>teacher, the, sandi, development, this, profes...</td>\n",
       "      <td>1690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.6951</td>\n",
       "      <td>year, meeting, observation, school, profession...</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contribution  \\\n",
       "0        1.0                   0.5216   \n",
       "1        3.0                   0.3238   \n",
       "2        4.0                   0.9551   \n",
       "3        5.0                   0.5604   \n",
       "4        6.0                   0.6951   \n",
       "\n",
       "                                            Keywords  Text  \n",
       "0  student, discussion, use, questioning, questio...   143  \n",
       "1  content, knowledge, concept, plan, lesson, ped...   292  \n",
       "2  activity, student, lesson, area, action, step,...  1752  \n",
       "3  teacher, the, sandi, development, this, profes...  1690  \n",
       "4  year, meeting, observation, school, profession...   129  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contribution\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Print top 5 rows\n",
    "sent_topics_sorteddf_mallet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Distribution of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Num_Documents</th>\n",
       "      <th>Perc_Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>student, step, action, learning, lesson, area,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>student, lesson, plan, assessment, work, datum...</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>student, step, action, learning, lesson, area,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>student, lesson, plan, assessment, work, datum...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>activity, student, lesson, area, action, step,...</td>\n",
       "      <td>675.0</td>\n",
       "      <td>0.1939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dominant_Topic                                     Topic_Keywords  \\\n",
       "0            13.0  student, step, action, learning, lesson, area,...   \n",
       "1            20.0  student, lesson, plan, assessment, work, datum...   \n",
       "2            13.0  student, step, action, learning, lesson, area,...   \n",
       "3            20.0  student, lesson, plan, assessment, work, datum...   \n",
       "4             4.0  activity, student, lesson, area, action, step,...   \n",
       "\n",
       "   Num_Documents  Perc_Documents  \n",
       "0            NaN             NaN  \n",
       "1          181.0          0.0520  \n",
       "2            NaN             NaN  \n",
       "3            6.0          0.0017  \n",
       "4          675.0          0.1939  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Format\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Print top 5 rows\n",
    "df_dominant_topics.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
